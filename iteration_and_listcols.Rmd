---
title: "listcols"
output: github_document
date: "2023-11-03"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rvest)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

set.seed(12345)
```

### Lists

```{r}
vec_numeric = c(1:4) 
vec_character = c("my", "name", "is", "courtney")

tibble(
  num = vec_numeric,
  char = vec_character
)
```

This only works because they're the same length. But we can circumvent this by using lists instead of a tibble

```{r}
l = 
  list(
    vec_numeric = 1:5,
    vec_char = LETTERS,
    matrix = matrix(1:10, nrow = 5, ncol = 2),
    summary = summary(rnorm(100))
  )
l
```

Accessing lists

```{r}
l$vec_char
l[[2]]
l[["summary"]]
```

## Loops

```{r}
list_norm_samples = 
  list(
    a = rnorm(20, 1, 5),
    b = rnorm(20, 0, 7),
    c = rnorm(20, 20, 1),
    d = rnorm(20, -45, 13)
  )
```

```{r}
mean_and_sd = function(x) {
  
  if (!is.numeric(x)) {
    
    stop("Argument should be numbers")
    
  }  else if (length(x) < 2) {
    
    stop("You need at least 2 numbers to get z scores")
    
  }
  
  mean_x = mean(x)
  
  sd_x = sd(x)
  
  tibble(
    mean = mean_x,
    sd = sd_x
  )
}
```

Could call the function for a:d, but that's annoying. 

```{r}
output = vector("list", length = 4)

for (i in 1:4) {
  output[[i]] = mean_and_sd(list_norm_samples[[i]])
}

output
```

## Now let's try using a map function

```{r}
output2 = map(list_norm_samples, mean_and_sd)
output2
```

## listcols in DFs

```{r}
listcol_df = 
  tibble(
    name = c("a", "b", "c", "d"),
    sample = list_norm_samples
  )

listcol_df |> 
  pull(sample)

mean_and_sd(listcol_df$sample[[1]])
mean_and_sd(listcol_df$sample[[2]])
mean_and_sd(listcol_df$sample[[3]])
mean_and_sd(listcol_df$sample[[4]])

map(listcol_df$sample, mean_and_sd)

listcol_df |> 
  mutate(mean_sd = map(sample, mean_and_sd)) |> 
  mutate(median = map(sample, median)) |> 
  select(name, mean_sd) |> 
  unnest(mean_sd)
```


## another example with NSDUH

```{r}
nsduh_url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

nsduh_html = read_html(nsduh_url)
```

Last time it looked like this:
```{r}
load_nsduh_data = function(html, table_number, outcome_name) {
  html |> 
  html_table() |> 
  nth(table_number) |>
  slice(-1) |> 
  select(-contains("P Value")) |>
  pivot_longer(
    -State,
    names_to = "age_year", 
    values_to = "percent") |>
  separate(age_year, into = c("age", "year"), sep = "\\(") |>
  mutate(
    year = str_replace(year, "\\)", ""),
    percent = str_replace(percent, "[a-c]$", ""),
    percent = as.numeric(percent),
    outcome = outcome_name) |>
  filter(!(State %in% c("Total U.S.", "Northeast", "Midwest", "South", "West")))
}

load_nsduh_data(html = nsduh_html, table_number = 1, outcome_name = "marj")

load_nsduh_data(html = nsduh_html, table_number = 4, outcome_name = "cocaine")
```

First let's try using a for loop

```{r}
output = vector("list", length = 3)
input_names = list("marj", "cocaine", "heroine")
input_tables = list(1, 4, 5)

for (i in 1:3) {
  
  output[[i]] = load_nsduh_data(nsduh_html, input_tables[[i]], input_names[[i]])
    
}

nsduh_df = bind_rows(output)

nsduh_df
```

Try again, using maps! 

FIrst, update the load data function to accomoadate an input tibble that has both the name of the table and the position of the table.

```{r}
load_nsduh_data = function(html, table_number) {
  html |> 
  html_table() |> 
  nth(table_number) |>
  slice(-1) |> 
  select(-contains("P Value")) |>
  pivot_longer(
    -State,
    names_to = "age_year", 
    values_to = "percent") |>
  separate(age_year, into = c("age", "year"), sep = "\\(") |>
  mutate(
    year = str_replace(year, "\\)", ""),
    percent = str_replace(percent, "[a-c]$", ""),
    percent = as.numeric(percent)) |>
  filter(!(State %in% c("Total U.S.", "Northeast", "Midwest", "South", "West")))
}


nsduh_df = 
  tibble(
    name = c("marj", "cocaine", "heroin"),
    number = c(1, 4, 5)
  ) |> 
  mutate(table = map(number, load_nsduh_data, html = nsduh_html)) |> 
  filter(name == "marj") |> 
  unnest(table)

nsduh_df
```


## Operations in nested data

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728", "USW00022534", "USS0023B17S"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2021-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(
      id, 
      USW00094728 = "CentralPark_NY", 
      USW00022534 = "Molokai_HI",
      USS0023B17S = "Waterhole_WA"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

```{r}
weather_nest_df = 
  weather_df |> 
  nest(df = date:tmin)
```

Can I regress tmax on tmin for each of these?

```{r}
central_park_df = 
  weather_nest_df |> 
  pull(df) |> 
  nth(1)
```

Let's fit a linear regression for central park

```{r}
lm(tmax ~ tmin, data = central_park_df)
```

Cool. Now let's do it for different dataframes! 

```{r}
weather_lm = function(df) {
  lm(tmax ~ tmin, data = df)
}

weather_lm(central_park_df)
```

Let's do a for loop: 

```{r}
input_list = weather_nest_df |> pull(df)
output = vector("list", length = 3)

for (i in 1:3) {
  output[[i]] = weather_lm(input_list[[i]])
}

weather_nest_df |> 
  mutate(models = map(df, weather_lm)) |> 
  unnest(df)
```

